import copy
import json
import os.path
import random

import issue_db_api
import numpy
from gensim import models

from ..config.core import Config
from ..config.arguments import Argument, StringArgument, IntArgument
from ..config.constraints import Constraint
from .base import AbstractUpSampler
from ..feature_generators import generators, FeatureEncoding
from ..embeddings.util import load_embedding
from .. import data_manager_bootstrap


class SynonymUpSampler(AbstractUpSampler):

    def upsample(self, indices, targets, labels, keys, *features):
        self._check_generators()
        self._check_feature_encoding()
        return super().upsample(indices, targets, labels, keys, *features)

    def upsample_class(self, indices, target, labels, keys, *features):
        # We need a number of things:
        # 1) the word-embedding used to generate the word2vec features
        # 2) the BowFreq index mapping
        # 3) the BOWNorm Index mapping
        # 4) The Word2Vec index mapping
        # 5) a word embedding for synonym detection.
        # 6) original issue text
        #
        # 1-4 are generator settings, 5 is a hyper-param for the up-sampler.
        # 6 is generated by the generator

        # Download substitution embedding
        db: issue_db_api.IssueRepository = self.conf.get('system.storage.database-api')
        embedding_id = self.hyper_params['word-embedding']
        embedding_filename = load_embedding(embedding_id, db, self.conf)

        #
        with open(data_manager_bootstrap.get_raw_text_file_name(self.conf)) as file:
            original_issue_text = json.load(file)
        generator_settings = []
        for filename in self.conf.get('system.storage.generators'):
            with open(filename) as file:
                data = json.load(file)
            match data['generator']:
                case 'Word2Vec1D':
                    generator_settings.append(
                        (
                            data['generator'],
                            (
                                data['settings']['word-to-index-mapping'],
                                models.KeyedVectors.load_word2vec_format(
                                    data['settings']['model'], binary=True
                                )
                            )
                        )
                    )
                case 'BOWFrequency' | 'BOWNormalized':
                    generator_settings.append(
                        (
                            data['generator'],
                            data['settings']['word-to-index-mapping']
                        )
                    )
                case _ as x:
                    raise ValueError(f'Unsupported feature generator: {x}')
        synonym_wv = models.KeyedVectors.load_word2vec_format(embedding_filename, binary=True)
        min_replace = self.hyper_params['min-replace']
        max_replace = self.hyper_params['max-replace']
        if min_replace > max_replace:
            raise ValueError('min-replace must be <= max-replace')
        n_synonyms = self.hyper_params['n-synonyms']
        failures = 0
        new_features = []
        for i in random.choices(indices, k=target - len(indices)):
            key = keys[i]
            text = original_issue_text[key]
            original_features = [copy.deepcopy(f[i]) for f in features]
            high = min(max_replace, len(text) // 4)
            if min_replace > high:
                low = high // 2
            else:
                low = min_replace
            replace_indices = random.sample(
                range(0, len(text)),
                k=random.randint(low, high)
            )
            for index in replace_indices:
                synonyms = synonym_wv.most_similar(text[index], topn=n_synonyms)
                candidates = [s
                              for s in synonyms
                              if self._is_valid_candidate(s, generator_settings)]
                if not candidates:
                    failures += 1
                new_word = random.choice(candidates)
                self._update_features(index,
                                      text[index],
                                      new_word,
                                      generator_settings,
                                      original_features)
            new_features.append(original_features)
        print(f'{failures} encountered during synonym replacement')
        return [numpy.asarray(x) for x in zip(*new_features)]

    @staticmethod
    def _is_valid_candidate(s, all_settings):
        for g, settings in zip(all_settings):
            match g:
                case 'BOWNormalized' | 'BOWFrequency':
                    return s in settings
                case 'Word2Vec1D':
                    return s in settings[0]
                case _:
                    raise ValueError(f'Unhandled generator: {g}')

    @staticmethod
    def _update_features(index, old_word, new_word, generator_settings, features):
        for f, (g, settings) in zip(features, generator_settings):
            match g:
                case 'BOWNormalized':
                    f[settings[old_word]] -= 1
                    f[settings[new_word]] += 1
                case 'BOWNormalized':
                    n = sum(f)
                    f[settings[old_word]] -= 1/n
                    f[settings[new_word]] += 1/n
                case 'Word2Vec1D':
                    f[index] = generator_settings[0][new_word]
                case _:
                    raise ValueError(f'Unhandled generator: {g}')

    @classmethod
    def get_constraints(cls) -> list[Constraint]:
        return super().get_constraints()

    @classmethod
    def get_arguments(cls):
        return super(SynonymUpSampler, SynonymUpSampler).get_arguments() | {
            'word-embedding': StringArgument(
                name='word-embedding',
                description='Path to the word embedding file to use to determine synonyms',
            ),
            'min-replace': IntArgument(
                name='min-replace',
                description='Minimum amount of words to replace per issue',
                minimum=1,
                default=10
            ),
            'max-replace': IntArgument(
                name='max-replace',
                description='Maximum amount of words to replace per issue',
                minimum=1,
                default=20
            ),
            'n-synonyms': IntArgument(
                name='n-synonyms',
                description='Amount of synonyms to consider per replacement',
                minimum=1,
                default=5
            )
        }

    def _check_feature_encoding(self):
        encodings = [
            generators[i].feature_encoding()
            for i in self.conf.get('run.input-mode')
        ]
        if any(e != FeatureEncoding.Numerical for e in encodings):
            raise ValueError('Can only apply SMOTE when using purely numerical features')

    def _check_generators(self):
        for i in self.conf.get('run.input-mode'):
            if i not in {'Word2Vec1D', 'BOWFrequency', 'BOWNormalized'}:
                raise ValueError(f'Unsupported feature generator for {self.__class__.__name__}: {i}')
